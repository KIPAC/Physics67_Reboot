{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de609a45",
   "metadata": {},
   "source": [
    "# More Propagation of Errors\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To use simulated experiments to deepen our understanding of propogation of errors.\n",
    "2. To use visual representations to further deepen our understanding of propogation of errors.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efad4821",
   "metadata": {},
   "source": [
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    numpy.expand_dims     | Adds a dimension to an array, useful for expanding two 1-D arrays into a 2-D array |\n",
    "| plt.imshow               | Makes a 2D-color plot by taking the values in a 2-D array to set a color scale |\n",
    "| plt.colorbar             | Adds a key corresponding to the color scale, e.g., when using plt.imshow |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d20d1d4a",
   "metadata": {},
   "source": [
    "# Visual understanding of propagation of errors\n",
    "\n",
    "### First example, how our estimate of A depends on our measurement of l\n",
    "\n",
    "We are going to run what is often called a \"Toy Simulation\" or a \"Toy Monte Carlo\" (\"Monte Carlo\" is a simulation technique where you generate a bunch of random numbers to simulate a range of possible outcomes).\n",
    "\n",
    "Specifically, we are going to simulation 10000 measurement of the length of the desk, assuming that the come from a \"Gaussian\" or \"Normal\" distribution that is centered on the value that we measured, but that have a standard deviation of 10% of that value.  \n",
    "\n",
    "Then we are going to see what happens to the distribution of outcomes.  I.e., of the measurements of the area of the desk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskArea(w, l, B, C):\n",
    "    return w * l * B**2 * C**2\n",
    "\n",
    "C_m = 8.\n",
    "B_m = 2.5\n",
    "l_m = 3.8\n",
    "w_m = 5.1\n",
    "A_m = deskArea(w_m, l_m, B_m, C_m)\n",
    "print(f\"Area of desk: {A_m:0.0f} cm^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45502ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will simulate 10000 measurements with drawn from a Normal distribtuion \n",
    "# The distribtuion is centered at l_m and has standard deviation of 0.1*l_m\n",
    "l_sim = rng.normal(loc=l_m, scale=0.1*l_m, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l_sim, bins=np.linspace(0.6*l_m, 1.4*l_m, 81))\n",
    "plt.xlabel(\"Length of desk [in books]\")\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Measurements of desk length: {np.mean(l_sim):0.2f} ± {np.std(l_sim):0.2f} [books]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6baec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((l_sim/l_m)-1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'Fractional Change: $\\Delta l / l$')\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean((l_sim/l_m)-1):0.2f} ± {np.std((l_sim/l_m)-1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9d121",
   "metadata": {},
   "source": [
    "### Questions for discussion:\n",
    "\n",
    "#### 3.1  Explain, in your own words, what is being shown in the two plots above.   How does this relate to the uncertainty on the measurement of $l$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0d48e",
   "metadata": {},
   "source": [
    "### Now, let's make a figure to show how A depends on l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a grid of value of l that covers a wide range around the value that we measured.\n",
    "l_grid = l_m*np.linspace(0.6, 1.4, 81)\n",
    "# And let's compute the Area of each value of l\n",
    "A_from_l = deskArea(w_m, l_grid, B_m, C_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot A version l_grid\n",
    "plt.plot(l_grid, A_from_l)\n",
    "plt.ylabel(r'Area of desk [$cm^2$]')\n",
    "plt.xlabel(r'Length of desk [units of books]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "plt.ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b540a1",
   "metadata": {},
   "source": [
    "### Questions for discussion:\n",
    "\n",
    "#### 4.1  Explain, again in your own words, what is being shown in the two plots above.  How does this relate to the formula shown above, in particular the formula that includes the partial derivatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab1a31",
   "metadata": {},
   "source": [
    "### Combining the sets of plots above.\n",
    "\n",
    "The first set of plots show use what range of measurments we might expect for $l$ and $\\frac{\\delta}{l}$.  The second plot shows use how $A$ changes if we change $l$.\n",
    "\n",
    "If we \"combine\" the two plots, we see the range of values that we might expect for $A$, given the uncertaintiy in $l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e963989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis0, axis1) = plt.subplots(2, 1, figsize=(4,6))\n",
    "\n",
    "axis0.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "axis1.hist((l_sim/l_m)-1, bins=(l_grid/l_m)-1)\n",
    "\n",
    "axis0.set_ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "axis1.set_ylabel(\"Simulated Trials [per bin]\")\n",
    "axis1.set_xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457346cd",
   "metadata": {},
   "source": [
    "What we mean when we say that we \"combine\" the two plots, is that for each value of $\\frac{\\Delta l}{l}$ on the x-axis, the top plot tells us the resulting change $\\frac{\\Delta A}{A}$, while the bottom plot tells us how likely that value of $\\frac{\\Delta l}{l}$ is to occur.  \n",
    "\n",
    "So, we see that large changes in $l$ are less likely that small changes.  And the distribution of outcomes from our little simulation give us a sense of the scatter we would expect in $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the area for the 10000 \"simulated\" measurements of l\n",
    "A_sim_1 = deskArea(w_m, l_sim, B_m, C_m)\n",
    "\n",
    "plt.hist(A_sim_1, bins=81)\n",
    "plt.xlabel(r'$A [{\\rm cm}^2]$')\n",
    "plt.ylabel(r'Trials [per bin]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Area of desk: {np.mean(A_sim_1):0.2f} ± {np.std(A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to compute the resulting relative change in A\n",
    "dA_over_A_sim_1 = (A_sim_1 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_1):0.2f} ± {np.std(dA_over_A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f30541",
   "metadata": {},
   "source": [
    "### Question for discussion.  \n",
    "\n",
    "#### 5.1 How can we interpret the two plots above?  What does it mean for our estimate of the uncertainty on $A$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f743d43",
   "metadata": {},
   "source": [
    "# Second example: how our estimate of A depends on C\n",
    "\n",
    "Now we are going to repeat the exercise, but this time we are going to vary $C$, our estimate of the length of the card in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = C_m*np.linspace(0.6, 1.4, 81)\n",
    "C_sim = rng.normal(loc=C_m, scale=0.1*C_m, size=10000)\n",
    "A_from_C = deskArea(w_m, l_m, B_m, C_m*np.linspace(0.6, 1.4, 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((C_m*np.linspace(0.6, 1.4, 81)/C_m)-1, (A_from_C/A_m)-1)\n",
    "plt.ylabel(r'Relative area of desk $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of card $\\Delta C / C$')\n",
    "plt.plot(np.linspace(-0.2,0.2,11), 2*np.linspace(-0.2,0.2,11), label=\"Tangent at zero\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc23465",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sim_2 = deskArea(w_m, l_m, B_m, C_sim)\n",
    "dA_over_A_sim_2 = (A_sim_2 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_2, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.05]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_2):0.2f} ± {np.std(dA_over_A_sim_2):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3ee23",
   "metadata": {},
   "source": [
    "### Questions for discussion.  \n",
    "\n",
    "#### 6.1 How can we interpret the two plots above?  What does it mean for our estimate of the uncertainty on $A$?  \n",
    "#### 6.2 Why does this differ from the results we got when we considered the variation in $A$ due to the variation in $l$?  \n",
    "#### 6.3 Why did we draw the tangent line on the figure a few cells up?   What does the tangent line correspond to in the equation for propagation of errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a2882",
   "metadata": {},
   "source": [
    "# Third example: how our estimate of A depends on the combination of l and w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2538681",
   "metadata": {},
   "source": [
    "#### First, how does lets see how A depends on changes in w and l.\n",
    "\n",
    "To estimate that, we are going to compute the area for a grid of values of w and l and plot the results.\n",
    "\n",
    "The x and y axes show the changes in w and l, respectively, the color scale shows the resulting change in A.\n",
    "\n",
    "What we see is that if both w and l were higher, the area would be larger, if they were both smaller the area would be smaller, and if one is large and the other smaller the effects tend to cancel.  This is hardly surprising.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aef350",
   "metadata": {},
   "outputs": [],
   "source": [
    "relValue = (deskArea(w_m*np.linspace(0.6, 1.4, 81),\n",
    "                     np.expand_dims(l_m*np.linspace(0.6, 1.4, 81), -1), B_m, C_m)/A_m ) - 1.\n",
    "\n",
    "plt.imshow(relValue, origin='lower', extent=(-0.4, 0.4, -0.4, 0.4)) \n",
    "plt.colorbar(label=r'Fractional change $\\Delta A / A$')\n",
    "plt.xlabel(r'Fractional change $\\Delta w / w$')\n",
    "plt.ylabel(r'Fractional change $\\Delta l / l$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de96022",
   "metadata": {},
   "source": [
    "#### Now lets consider how likely it is that we get particular sets of changes.\n",
    "\n",
    "These plots show the number of times we get a particular set of changes in our simulations.\n",
    "\n",
    "Let's consider changes in both $w$ and $l$, which are independent measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e07b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have l_sim, so we just need w_sim\n",
    "w_sim = rng.normal(loc=w_m, scale=0.1*w_m, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df330394",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d((w_sim/w_m)-1, (l_sim/l_m)-1., bins=np.linspace(-0.4,0.4,25))\n",
    "plt.xlabel(r'Fractional change $\\Delta w / w$')\n",
    "plt.ylabel(r'Fractional change $\\Delta l / l$')\n",
    "plt.colorbar(label=r'Number of simulations [per bin]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0f3dd",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 7.1 This plot, and the plot before, are two dimensional versions of the plots what we used to illustrate how changes in one input variable cause changes in the outcome.  Explain these plots, and what we can learn from them, in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c7f3d",
   "metadata": {},
   "source": [
    "### Effect of changing both l and w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d907405",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sim_3 = deskArea(w_sim, l_sim, B_m, C_m)\n",
    "dA_over_A_sim_3 = (A_sim_3 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_3, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.04]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_3):0.2f} ± {np.std(dA_over_A_sim_3):0.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf4aead8",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 8.1 Put it all together.  Explain this plot in terms of what we have done and your understanding of propagation of errors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3d6f872",
   "metadata": {},
   "source": [
    "## A special case of error propagation\n",
    "\n",
    "Recall the exercise from the previous notebook about measuring the energy flux from the sun. We're going to focus on measuring $n_\\gamma$, the number of photons measured by our photodetector in the measurement time $t$.\n",
    "\n",
    "In order to write down the distribution for $n_\\gamma$, we need to know the mean value. Let's assume the energy flux on Earth is 1000 Watts/m^2 (our hypothetical experimenter doesn't know this yet, though!) \n",
    "\n",
    "We'll make the approximation that all of the photons have energy 3 eV (in reality, the photon energy from the sun follows a [blackbody distribution](https://en.wikipedia.org/wiki/Black-body_radiation)) and our photodetector is 1 mm $^2$ in area. This means we expect about $10^{15}$ photons to hit our detector every second.\n",
    "\n",
    "The number of photons hitting the detector every minute will therefore follow a Poisson distribution with mean $\\lambda = 1e15$ photons/second. So the probability of measuring $k$ photons in one second is given by:\n",
    "$$\n",
    "P(k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1678ce7b",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "Let's simulate what a single set of measurements might look like. Imagine we leave our photodetector in the sun for 10000 seconds (about 3 hours) and record the number of photons counted in each minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = rng.poisson(1e15, 10000)\n",
    "bins = np.linspace(1e15-1e8, 1e15+1e8, 100)\n",
    "plt.hist(sample1, bins)\n",
    "\n",
    "print(f\"Sample mean : {np.mean(sample1):0.3g}\")\n",
    "print(f\"Standard dev: {np.std(sample1):0.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55073fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample mean : {np.mean(sample1):0.3g}\")\n",
    "print(f\"Standard dev: {np.std(sample1):0.3g}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9755fa5",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 9.1 Do the sample mean and standard deviation match what you expect from the Poisson distribution?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7af156af",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "Now imagine that we perform this measurement every day for 100 days. At the end of each day, we write down the mean and standard deviation of the dataset for that day. (We'll assume we are drawing from the same Poisson distribution every time, although in reality it will change depending on the Earth's position in its orbit.)\n",
    "\n",
    "At the end of the 100 days, we take the 100 means and plot them in a histogram. Here's what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a 100x10000 array, where each row represents a single day's dataset\n",
    "sample_array = rng.poisson(1e15, size=(100, 10000)) \n",
    "\n",
    "# Numpy will calculate the mean and standard deviation of each of the 100 rows (axis 0) \n",
    "# and put them together into an array\n",
    "means = np.mean(sample_array, axis=0)\n",
    "stdevs = np.std(sample_array, axis=0)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "# Note that the axes are different from the previous plot!\n",
    "bins = np.linspace(1e15-1e7, 1e15+1e7, 100)\n",
    "plt.hist(means, bins)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55405ced",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "After 100 days, we decide that we need more data. We buy 9 more photosensors (so now we have 10) and again record 100 days of data, giving us 10000 total samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_array = rng.poisson(1e15, size=(1000, 10000)) \n",
    "\n",
    "means = np.mean(sample_array, axis=0)\n",
    "stdevs = np.std(sample_array, axis=0)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e7, 1e15+1e7, 100)\n",
    "plt.hist(means, bins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "558d6d16",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "\n",
    "Somebody is cleaning out the lab next door, and they find 90 photosensors that we can use for our experiment, for a total of 100 sensors. After another 100 days, we will have 10,000 samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this will take a few seconds to run!\n",
    "sample_array = rng.poisson(1e15, size=(10000, 10000)) \n",
    "\n",
    "means = np.mean(sample_array, axis=0)\n",
    "stdevs = np.std(sample_array, axis=0)\n",
    "\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e7, 1e15+1e7, 100)\n",
    "plt.hist(means, bins)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e41814a7",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 10.1 What do you notice about the shapes of the distributions for different numbers of observation days? Is this what you expect?\n",
    "\n",
    "##### 10.2 What do you notice about the mean and standard deviation of each distribution? Be specific!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b06decd2",
   "metadata": {},
   "source": [
    "### Comparing with theory\n",
    "\n",
    "Now let's compare our simulation data with what we should expect to see. To do so, we have to think about what data we are really analyzing. For experiment 1, we have a bunch of observations in a single dataset. For experiments 2, 3 and 4, we have many datasets, and what we are really plotting is the mean of each dataset. So what we want to calculate is really the *mean of the means* and the *standard deviation of the means*.\n",
    "\n",
    "Calculating the mean of the means is simple enough:\n",
    "$$\n",
    "\\Mu(\\mu_i)= \\frac{1}{N} \\sum_{i = 0}^N \\mu_i\n",
    "$$\n",
    "\n",
    "What about the *standard deviation of the means* ($\\sigma_\\Mu$)? We can use the general formula for propagation of errors:\n",
    "$$\n",
    "\\sigma_f^{2}(x_i) = \\sum_i \\left(\\frac{\\partial f}{\\partial x_i} \\delta x_i\\right)^2\n",
    "$$\n",
    "\n",
    "In this case, the function of interest is the mean $M$. The $x_i$s are the mean of each measurement ($\\mu_i$), and the $\\delta x_i$ are the standard deviation from each measurement ($\\sigma_i$).\n",
    "$$\n",
    "\\sigma_\\Mu^{2}(\\mu_i) = \\sum_i \\left(\\frac{\\partial \\Mu}{\\partial \\mu_i} \\sigma_i\\right)^2\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18d584f9",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "##### 11.1 What are the partial derivatives $\\partial \\Mu / \\partial \\mu_i$?\n",
    "\n",
    "##### 11.2 Plug in for the partial derivatives and simplify to show that $\\sigma_\\Mu = \\sigma_\\mu/\\sqrt{N}$\n",
    "\n",
    "Hint: Keep in mind that we are drawing from the same distribution every time we make a measurement. What does this tell you about the $\\mu_i$ and $\\sigma_i$ you expect from each measurement?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0ff41ff",
   "metadata": {},
   "source": [
    "### Surprise! We've just derived the formula for the standard error on the mean.\n",
    "\n",
    "##### 11.3 Does this exercise contribute to your understanding of the standard error? If so, how? How does the standard error on the mean differ from the individual standard deviations of each measurement?\n",
    "\n",
    "##### 11.4 Plug in numbers to show that the means and standard errors that we found in the simulations above agree with the formula $\\sigma_\\Mu = \\sigma_\\mu / \\sqrt{N}$. Please show your work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
